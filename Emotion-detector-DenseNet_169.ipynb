{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> EMOTION DETECTOR </center>\n","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:21:47.129681Z","iopub.execute_input":"2021-10-28T16:21:47.129947Z","iopub.status.idle":"2021-10-28T16:21:47.135185Z","shell.execute_reply.started":"2021-10-28T16:21:47.129921Z","shell.execute_reply":"2021-10-28T16:21:47.134018Z"}}},{"cell_type":"markdown","source":"<a id=\"im\"></a>\n# <center>IMPORTING LIBRARIES</center> ","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:25:41.041154Z","iopub.execute_input":"2021-10-28T16:25:41.041859Z","iopub.status.idle":"2021-10-28T16:25:41.047378Z","shell.execute_reply.started":"2021-10-28T16:25:41.041821Z","shell.execute_reply":"2021-10-28T16:25:41.046222Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report\n\n\nfrom IPython.display import clear_output\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-12-01T08:07:46.632023Z","iopub.execute_input":"2021-12-01T08:07:46.632279Z","iopub.status.idle":"2021-12-01T08:07:54.399109Z","shell.execute_reply.started":"2021-12-01T08:07:46.632207Z","shell.execute_reply":"2021-12-01T08:07:54.398287Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"hp\"></a>\n# <center>HYPERPARAMETRERS AND DIRECTORIES</center>","metadata":{}},{"cell_type":"code","source":"train_dir = \"../input/emotion-detection-fer/train\"\ntest_dir = \"../input/emotion-detection-fer/test\"\n\nSEED = 12\nIMG_HEIGHT = 48\nIMG_WIDTH = 48\nBATCH_SIZE = 64\nEPOCHS = 30\nFINE_TUNING_EPOCHS = 20\nLR = 0.01\nNUM_CLASSES = 7\nEARLY_STOPPING_CRITERIA=3\nCLASS_LABELS  = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', \"Surprise\"]\nCLASS_LABELS_EMOJIS = [\"üëø\", \"ü§¢\" , \"üò±\" , \"üòä\" , \"üòê \", \"üòî\" , \"üò≤\" ]","metadata":{"execution":{"iopub.status.busy":"2021-12-01T08:07:54.401918Z","iopub.execute_input":"2021-12-01T08:07:54.402417Z","iopub.status.idle":"2021-12-01T08:07:54.409305Z","shell.execute_reply.started":"2021-12-01T08:07:54.402380Z","shell.execute_reply":"2021-12-01T08:07:54.408686Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"data\"></a>\n# <center> DATA LOADING AND PRE-PROCESSING</center>","metadata":{}},{"cell_type":"code","source":"preprocess_fun = tf.keras.applications.densenet.preprocess_input\n\ntrain_datagen = ImageDataGenerator(horizontal_flip=True,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.05,\n                                   rescale = 1./255,\n                                   validation_split = 0.2,\n                                   preprocessing_function=preprocess_fun\n                                  )\ntest_datagen = ImageDataGenerator(rescale = 1./255,\n                                  validation_split = 0.2,\n                                  preprocessing_function=preprocess_fun)\n\ntrain_generator = train_datagen.flow_from_directory(directory = train_dir,\n                                                    target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                    batch_size = BATCH_SIZE,\n                                                    shuffle  = True , \n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    subset = \"training\",\n                                                    seed = 12\n                                                   )\n\nvalidation_generator = test_datagen.flow_from_directory(directory = train_dir,\n                                                         target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                         batch_size = BATCH_SIZE,\n                                                         shuffle  = True , \n                                                         color_mode = \"rgb\",\n                                                         class_mode = \"categorical\",\n                                                         subset = \"validation\",\n                                                         seed = 12\n                                                        )\n\ntest_generator = test_datagen.flow_from_directory(directory = test_dir,\n                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                    batch_size = BATCH_SIZE,\n                                                    shuffle  = True , \n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    seed = 12\n                                                  )","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-01T08:07:54.417498Z","iopub.execute_input":"2021-12-01T08:07:54.417783Z","iopub.status.idle":"2021-12-01T08:08:22.322225Z","shell.execute_reply.started":"2021-12-01T08:07:54.417747Z","shell.execute_reply":"2021-12-01T08:08:22.321503Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Images with different emotions","metadata":{}},{"cell_type":"code","source":"# Helper Functions\ndef display_one_image(image, title, subplot, color):\n    plt.subplot(subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    plt.title(title, fontsize=16)\n    \ndef display_nine_images(images, titles, title_colors=None):\n    subplot = 331\n    plt.figure(figsize=(13,13))\n    for i in range(9):\n        color = 'black' if title_colors is None else title_colors[i]\n        display_one_image(images[i], titles[i], 331+i, color)\n    plt.tight_layout()\n    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n    plt.show()\n\ndef image_title(label, prediction):\n  # Both prediction (probabilities) and label (one-hot) are arrays with one item per class.\n    class_idx = np.argmax(label, axis=-1)\n    prediction_idx = np.argmax(prediction, axis=-1)\n    if class_idx == prediction_idx:\n        return f'{CLASS_LABELS[prediction_idx]} [correct]', 'black'\n    else:\n        return f'{CLASS_LABELS[prediction_idx]} [incorrect, should be {CLASS_LABELS[class_idx]}]', 'red'\n\ndef get_titles(images, labels, model):\n    predictions = model.predict(images)\n    titles, colors = [], []\n    for label, prediction in zip(classes, predictions):\n        title, color = image_title(label, prediction)\n        titles.append(title)\n        colors.append(color)\n    return titles, colors\n\nimg_datagen = ImageDataGenerator(rescale = 1./255)\nimg_generator = img_datagen.flow_from_directory(directory = train_dir,\n                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                    batch_size = BATCH_SIZE,\n                                                    shuffle  = True , \n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    seed = 12\n                                                  )\nclear_output()\n\nimages, classes = next(img_generator)\nclass_idxs = np.argmax(classes, axis=-1) \nlabels = [CLASS_LABELS[idx] for idx in class_idxs]\ndisplay_nine_images(images, labels)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-01T08:08:22.323375Z","iopub.execute_input":"2021-12-01T08:08:22.323789Z","iopub.status.idle":"2021-12-01T08:08:25.363718Z","shell.execute_reply.started":"2021-12-01T08:08:22.323751Z","shell.execute_reply":"2021-12-01T08:08:25.362964Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Data distribution (count) among differnt emotions","metadata":{}},{"cell_type":"code","source":"fig = px.bar(x = CLASS_LABELS_EMOJIS,\n             y = [list(train_generator.classes).count(i) for i in np.unique(train_generator.classes)] , \n             color = np.unique(train_generator.classes) ,\n             color_continuous_scale=\"Emrld\") \nfig.update_xaxes(title=\"Emotions\")\nfig.update_yaxes(title = \"Number of Images\")\nfig.update_layout(showlegend = True,\n    title = {\n        'text': 'Train Data Distribution ',\n        'y':0.95,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-01T08:08:25.364714Z","iopub.execute_input":"2021-12-01T08:08:25.365444Z","iopub.status.idle":"2021-12-01T08:08:26.228666Z","shell.execute_reply.started":"2021-12-01T08:08:25.365415Z","shell.execute_reply":"2021-12-01T08:08:26.227870Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"model\"></a>\n# <center> DenseNet169 Transfer Learning  </center>","metadata":{}},{"cell_type":"code","source":"def feature_extractor(inputs):\n    feature_extractor = tf.keras.applications.DenseNet169(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3),\n                                               include_top=False,\n                                               weights=\"imagenet\")(inputs)\n    \n    return feature_extractor\n\ndef classifier(inputs):\n    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n    x = tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(1024, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    x = tf.keras.layers.Dense(512, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n    x = tf.keras.layers.Dropout(0.5) (x)\n    x = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"classification\")(x)\n    \n    return x\n\ndef final_model(inputs):\n    densenet_feature_extractor = feature_extractor(inputs)\n    classification_output = classifier(densenet_feature_extractor)\n    \n    return classification_output\n\ndef define_compile_model():\n    \n    inputs = tf.keras.layers.Input(shape=(IMG_HEIGHT ,IMG_WIDTH,3))\n    classification_output = final_model(inputs) \n    model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n     \n    model.compile(optimizer=tf.keras.optimizers.SGD(0.1), \n                loss='categorical_crossentropy',\n                metrics = ['accuracy'])\n  \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-01T08:08:26.230020Z","iopub.execute_input":"2021-12-01T08:08:26.230281Z","iopub.status.idle":"2021-12-01T08:08:26.241954Z","shell.execute_reply.started":"2021-12-01T08:08:26.230245Z","shell.execute_reply":"2021-12-01T08:08:26.241307Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Summary of model","metadata":{}},{"cell_type":"code","source":"model = define_compile_model()\nclear_output()\n\n# Feezing the feature extraction layers\nmodel.layers[1].trainable = False\n\nmodel.summary()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-01T08:08:26.243280Z","iopub.execute_input":"2021-12-01T08:08:26.243794Z","iopub.status.idle":"2021-12-01T08:08:34.954520Z","shell.execute_reply.started":"2021-12-01T08:08:26.243759Z","shell.execute_reply":"2021-12-01T08:08:34.953725Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"train\"></a>\n# <center> Training and Fine-Tuning </center> ","metadata":{}},{"cell_type":"markdown","source":"## Training model with freezed layers of DenseNer169","metadata":{}},{"cell_type":"code","source":"earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n                                                         patience=EARLY_STOPPING_CRITERIA,\n                                                         verbose= 1 ,\n                                                         restore_best_weights=True\n                                                        )\n\nhistory = model.fit(x = train_generator,\n                    epochs = EPOCHS ,\n                    validation_data = validation_generator , \n                    callbacks= [earlyStoppingCallback])\n\nhistory = pd.DataFrame(history.history)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-01T08:08:34.955941Z","iopub.execute_input":"2021-12-01T08:08:34.956456Z","iopub.status.idle":"2021-12-01T08:21:49.587975Z","shell.execute_reply.started":"2021-12-01T08:08:34.956415Z","shell.execute_reply":"2021-12-01T08:21:49.587154Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Fine Tuning","metadata":{}},{"cell_type":"code","source":"# Un-Freezing the feature extraction layers for fine tuning \nmodel.layers[1].trainable = True\n\nmodel.compile(optimizer=tf.keras.optimizers.SGD(0.001), #lower learning rate\n                loss='categorical_crossentropy',\n                metrics = ['accuracy'])\n\nhistory_ = model.fit(x = train_generator,epochs = FINE_TUNING_EPOCHS ,validation_data = validation_generator)\nhistory = history.append(pd.DataFrame(history_.history) , ignore_index=True)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-01T08:21:49.590800Z","iopub.execute_input":"2021-12-01T08:21:49.591083Z","iopub.status.idle":"2021-12-01T08:41:45.868148Z","shell.execute_reply.started":"2021-12-01T08:21:49.591045Z","shell.execute_reply":"2021-12-01T08:41:45.867460Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Training plots","metadata":{}},{"cell_type":"code","source":"x = px.line(data_frame= history , y= [\"accuracy\" , \"val_accuracy\"] ,markers = True )\nx.update_xaxes(title=\"Number of Epochs\")\nx.update_yaxes(title = \"Accuracy\")\nx.update_layout(showlegend = True,\n    title = {\n        'text': 'Accuracy vs Number of Epochs',\n        'y':0.94,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nx.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-01T08:41:45.869620Z","iopub.execute_input":"2021-12-01T08:41:45.869875Z","iopub.status.idle":"2021-12-01T08:41:45.960999Z","shell.execute_reply.started":"2021-12-01T08:41:45.869839Z","shell.execute_reply":"2021-12-01T08:41:45.960310Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"x = px.line(data_frame= history , \n            y= [\"loss\" , \"val_loss\"] , markers = True )\nx.update_xaxes(title=\"Number of Epochs\")\nx.update_yaxes(title = \"Loss\")\nx.update_layout(showlegend = True,\n    title = {\n        'text': 'Loss vs Number of Epochs',\n        'y':0.94,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nx.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-01T08:41:45.962351Z","iopub.execute_input":"2021-12-01T08:41:45.962822Z","iopub.status.idle":"2021-12-01T08:41:46.031738Z","shell.execute_reply.started":"2021-12-01T08:41:45.962786Z","shell.execute_reply":"2021-12-01T08:41:46.030775Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"vis\"></a>\n# <center> Visualizing Results </center> ","metadata":{}},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_generator , verbose = 0)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T08:41:46.033148Z","iopub.execute_input":"2021-12-01T08:41:46.033411Z","iopub.status.idle":"2021-12-01T08:42:30.171020Z","shell.execute_reply.started":"2021-12-01T08:41:46.033375Z","shell.execute_reply":"2021-12-01T08:42:30.170264Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"probs = model.predict(test_generator)\ny_test =test_generator.classes\ny_preds = probs >0.5\ny_preds =np.argmax(y_preds, axis=1)\nprint(classification_report(y_test , y_preds))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-01T08:42:30.172351Z","iopub.execute_input":"2021-12-01T08:42:30.172819Z","iopub.status.idle":"2021-12-01T08:42:38.593077Z","shell.execute_reply.started":"2021-12-01T08:42:30.172777Z","shell.execute_reply":"2021-12-01T08:42:38.592177Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.save(\"Emotion_recognition.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-12-01T08:45:50.844435Z","iopub.execute_input":"2021-12-01T08:45:50.844997Z","iopub.status.idle":"2021-12-01T08:45:51.698812Z","shell.execute_reply.started":"2021-12-01T08:45:50.844958Z","shell.execute_reply":"2021-12-01T08:45:51.698006Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}